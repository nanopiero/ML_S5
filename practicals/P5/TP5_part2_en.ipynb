{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Practical NÂ°5:** Deep Learning to Characterize Probability Distributions in an Image Space."
      ],
      "metadata": {
        "id": "MSgiKnAs1BbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plan\n",
        "\n",
        "##Part I:\n",
        "\n",
        "Quantile Regression.\n",
        "* Appropriate Cost Function\n",
        "* Quantile Regression: A First Example\n",
        "* Simultaneous Quantile Regression\n",
        "\n",
        "\n",
        "##Part II:\n",
        "\n",
        "Sampling through a Generative Method: The Example of GANs.\n",
        "* Basic Principle and Initial Training\n",
        "* Limitations\n",
        "* Some Solutions\n",
        "\n",
        "\n",
        "Duration: 3 hours"
      ],
      "metadata": {
        "id": "AvaKH1dZvg2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Part II:\n",
        "\n",
        "In the following exercises, two tools are presented to measure the gap between two probability distributions: the Kullback-Leibler divergence and the Wasserstein distance."
      ],
      "metadata": {
        "id": "H-qORHxn2zzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling using a Generative Method: The Example of GANs.\n",
        "\n",
        "In this section, we aim to characterize a distribution in an image domain, rather than at the pixel level.\n",
        "\n",
        "In high dimensions, especially on real images, the joint distribution is not modelable. It is not feasible to seek its density. However, we can attempt to sample from this distribution by relying on an existing set of images.\n",
        "We will start by doing this without worrying about the conditional aspect:\n",
        "in **Exercise 3**, the goal is to build a **generative model** that samples a domain of synthetic images.\n",
        "\n",
        "Most recent generative models are primarily constructed from deep neural networks. In the field of image generation, one of the main approaches is based on **GANs** (Generative Adversarial Networks). **Exercise 3** illustrates this approach in its simplest version, while **Exercise 4** presents some variations.\n",
        "Finally, **Exercise 5** gives us the opportunity to revisit the conditional aspect. The GAN approach is modified to sample from an implicit conditional distribution."
      ],
      "metadata": {
        "id": "--emH6d31Ahl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1** A first GAN.\n",
        "\n"
      ],
      "metadata": {
        "id": "qndq7kQQISSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The principle of GAN is simple. We have:\n",
        "- A random vector $Z$, sampled from a simple distribution, for example, a centered reduced Gaussian vector.\n",
        "- A generative network $G_\\theta$ ($\\theta$ represents the network's weights) that generates an image $G_\\theta(Z)$.\n",
        "- A discriminator network $D_\\rho$ (similar notation as before), ending with a sigmoid function that classifies an image $x$ as \"real\" ($D_\\rho(x) > 0.5$) or \"fake\" ($D_\\rho(x) < 0.5$).\n",
        "\n",
        "In the following, we omit the notations $\\rho$ and $\\theta$.\n",
        "\n",
        "The algorithm consists of training $G$ and $D$ on adversarial tasks:\n",
        "- $D_\\rho$ is trained to distinguish images from the dataset ($x^{(i)}$) from images generated by $G_\\theta$ (denoted as $G(z^{(i)})$). In the [original GAN paper](https://arxiv.org/abs/1406.2661), the authors use cross-entropy as the cost function. For a pair of two images, one fake and the other real, the cost is written as:\n",
        "  $$  - {\\bigg [} \\ln(D(x^{(i)})) + \\ln(1 - D(G(z^{(i)})) {\\bigg ]}$$\n",
        "\n",
        "- $G_\\theta$ is trained to \"fool\" the discriminator with the adversarial cost function:\n",
        "  $$  \\ln(1 - D(G(z^{(i)}))) $$\n",
        "\n",
        "A theoretical analysis of the problem is covered in the supplementary exercise sheet. Here, we implement the algorithm on synthetic images."
      ],
      "metadata": {
        "id": "bmFMn35Djs05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "# import torch.nn.parallel\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms"
      ],
      "metadata": {
        "id": "8IQ1Flnxj_Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/relmonta/ml-student.git\n",
        "! cp ml-student/TP5/* ."
      ],
      "metadata": {
        "id": "9IgxkX7NrrSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_GANs import *"
      ],
      "metadata": {
        "id": "rBewKJe7i4oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first define an image generation problem. The following function samples the random image $X$ and the random vector $Z$:"
      ],
      "metadata": {
        "id": "kFNkLntQujEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rectangle proportion in the image:\n",
        "lambda_rec = 0.0\n",
        "\n",
        "x, z = gen_DCGAN(6, lambda_rec=lambda_rec)\n",
        "\n",
        "# Clean versions (individual cells)\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "see_batch_2D(x, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "see_batch_2D(z, 6, fig3, k=0, min_scale=0, max_scale=1)\n"
      ],
      "metadata": {
        "id": "JvM6l5tfG4cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** The vector $Z$ is an image. What type of network is suitable for $G$? Instantiate it."
      ],
      "metadata": {
        "id": "QKi_mw5LueFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_channels, n_classes, size = 1, 1, 8\n",
        "\n",
        "netG = UNet(n_channels, n_classes, size).cuda()"
      ],
      "metadata": {
        "id": "5KtabSIMHVXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** The Discriminator class is used to encode the discriminator. Instantiate it and use the *weight_init* function to initialize the network's weights. What type of network do you obtain in this way?"
      ],
      "metadata": {
        "id": "dxPpDZRuvqbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf, nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if 'Conv' in classname:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif 'BatchNorm' in classname:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "ndf = 32\n",
        "nc = 1\n",
        "netD = Discriminator(ndf,nc).cuda()\n",
        "netD.apply(weights_init)"
      ],
      "metadata": {
        "id": "Z0wU8ftRHUSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now specify some training parameters (most of them are standard for GANs):"
      ],
      "metadata": {
        "id": "3mSpp0qRw-TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing the seed (to reproduce results)\n",
        "manualSeed = 1\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Number of parallel processes:\n",
        "workers = 2\n",
        "\n",
        "# Image size\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels\n",
        "nc = 1\n",
        "\n",
        "# Batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Number of batches per epoch\n",
        "num_batches = 200\n",
        "num_epochs = 10\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparameter for Adam\n",
        "beta1 = 0.5  # Sometimes simply 0.\n",
        "\n",
        "# Number of GPUs\n",
        "ngpu = 1\n",
        "\n",
        "# Cross-entropy\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Labels for real and fake images\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "cSzW08JSGbKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To observe how G(z) evolves with z fixed along the training:\n",
        "_ , fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "fixed_z = fixed_z.cuda()"
      ],
      "metadata": {
        "id": "PKjdWbBBxedy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Commenter le code ci-dessous aprÃ¨s l'avoir lancÃ©:"
      ],
      "metadata": {
        "id": "2gSP_UYGxokD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists for stats\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches):\n",
        "\n",
        "        # Sampling X and Z\n",
        "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "        # Real images\n",
        "        x = x.cuda()\n",
        "\n",
        "        # White noise\n",
        "        z = z.cuda()\n",
        "\n",
        "        # STEP 1: Discriminator optimization\n",
        "\n",
        "        # Zeroing discriminator gradients\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Discrimination of real images\n",
        "        D_real = netD(x).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of real images\n",
        "        b_size = x.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
        "        errD_real = criterion(D_real, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        # To calculate accuracy:\n",
        "        D_real = D_real.mean().item()\n",
        "\n",
        "        # Generated images\n",
        "        fake = netG(z.cuda())\n",
        "\n",
        "        # Discrimination of generated images\n",
        "        # .detach() -> we do not calculate gradients with respect to netG weights\n",
        "        # at this step\n",
        "        D_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of generated images\n",
        "        label.fill_(fake_label)\n",
        "        errD_fake = criterion(D_fake, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # Overall loss:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Update discriminator weights\n",
        "        optimizerD.step()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake = D_fake.mean().item()\n",
        "\n",
        "        # STEP 2: Generator optimization\n",
        "        netG.zero_grad()\n",
        "\n",
        "        # Regeneration, but gradients calculation is maintained\n",
        "        D_fake2 = netD(fake).view(-1)\n",
        "\n",
        "        # Update generator weights\n",
        "        label.fill_(real_label)\n",
        "        errG = criterion(D_fake2, label)\n",
        "        errG.backward()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake2 = D_fake2.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, num_batches,\n",
        "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Store generated images from \"fixed_z\" every hundred epochs\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_z).detach().cpu()\n",
        "            img_list.append(fake)\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "PxWy6OkTzI5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Plot the evolution of the cost functions for the generator and discriminator. Visualize the successive images."
      ],
      "metadata": {
        "id": "YBCnpIJFyIpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qStDjyBbHzK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ],
      "metadata": {
        "id": "7p6cQCvTIGKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the Generator:\n",
        "_ , z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "z = z.cuda()\n",
        "fake = netG(z).detach()\n",
        "\n",
        "fig = plt.figure(1, figsize=(12, 4))\n",
        "voir_batch2D(fake.cpu(), 14, fig1, k=0, min_scale=0,max_scale=1)"
      ],
      "metadata": {
        "id": "tcyKBeWzIH5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training is not yet perfect (improvement could be achieved with more epochs), but the generator manages to sample images that are roughly close to the original images. It has started to reproduce intersections between cells. \\\n",
        "One could verify this quantitatively by comparing classical statistics (mean per pixel, standard deviation, etc.) or even spectral densities."
      ],
      "metadata": {
        "id": "Y-0iCuAnOKh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Restart training with additional rectangles on the image. Visualize and comment on the results."
      ],
      "metadata": {
        "id": "xsozbuqsyhnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rectangle proportion in the image :\n",
        "lambda_rec = 0.00025\n",
        "\n",
        "x , z = gen_DCGAN(6,lambda_rec = lambda_rec)\n",
        "\n",
        "# Propre versions (only cells)\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(x, 6, fig1, k=0, min_scale=0,max_scale=1)\n",
        "\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(z, 6, fig3, k=0, min_scale=0,max_scale=1)"
      ],
      "metadata": {
        "id": "UDrBZW-wME-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing the seed (to reproduce results)\n",
        "manualSeed = 1\n",
        "num_epochs = 20\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "netD = Discriminator().cuda()\n",
        "netD.apply(weights_init)\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Lists for stats\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches):\n",
        "        # Sampling X and Z\n",
        "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "        # Real images\n",
        "        x = x.cuda()\n",
        "\n",
        "        # White noise\n",
        "        z = z.cuda()\n",
        "\n",
        "        # STEP 1: Discriminator optimization\n",
        "\n",
        "        # Zeroing discriminator gradients\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Discrimination of real images\n",
        "        D_real = netD(x).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of real images\n",
        "        b_size = x.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
        "        errD_real = criterion(D_real, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        # To calculate accuracy:\n",
        "        D_real = D_real.mean().item()\n",
        "\n",
        "        # Generated images\n",
        "        fake = netG(z.cuda())\n",
        "\n",
        "        # Discrimination of generated images\n",
        "        # .detach() -> we do not calculate gradients with respect to netG weights\n",
        "        # at this step\n",
        "        D_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of generated images\n",
        "        label.fill_(fake_label)\n",
        "        errD_fake = criterion(D_fake, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # Overall loss:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Update discriminator weights\n",
        "        optimizerD.step()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake = D_fake.mean().item()\n",
        "\n",
        "        # STEP 2: Generator optimization\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "\n",
        "        # Regeneration, but gradients calculation is maintained\n",
        "        D_fake2 = netD(fake).view(-1)\n",
        "\n",
        "        # Update generator weights\n",
        "        errG = criterion(D_fake2, label)\n",
        "        errG.backward()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake2 = D_fake2.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, num_batches,\n",
        "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Store generated images from \"fixed_z\" every hundred epochs\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_z.cuda()).detach().cpu()\n",
        "            img_list.append(fake)\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "SsD4m1ksLn9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ],
      "metadata": {
        "id": "BtIKuBQfP5Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the generated images, a clear issue arises: the same rectangles reappear in multiple images of the batch. This problem is called 'mode collapse.' It often occurs with GANs and can complicate their training."
      ],
      "metadata": {
        "id": "FNl_1vUXVZv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4** Wasserstein-GANs"
      ],
      "metadata": {
        "id": "O7pVjRQIUCJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To facilitate the convergence of GANs, several approaches have been explored. In particular:\n",
        "- Giving the discriminator more time to converge at each step.\n",
        "- Changing the metric on which GAN convergence is based (Jensen-Shannon divergence). Wasserstein distance has emerged as an effective alternative.\n",
        "\n",
        "In this exercise, both of these approaches are implemented."
      ],
      "metadata": {
        "id": "LIIq4Ypsyf2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** In the following code, gradient control is performed using two methods. The first, presented in the paper introducing WGANs [(Wasserstein-GANs)](https://arxiv.org/abs/1701.07875), simply involves thresholding the weights of neurons (*clamp* in the code).\n",
        "The second involves [penalizing gradients](https://arxiv.org/pdf/1704.00028.pdf) of the discriminator in the vicinity of the batch images, further improving performance.\\\n",
        "Run the following cells up to the training loop."
      ],
      "metadata": {
        "id": "BUnziPsr3zO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf=32, nc=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# Example usage:\n",
        "# netD = Discriminator()\n",
        "# or\n",
        "# netD = Discriminator(ndf=32, nc=1)"
      ],
      "metadata": {
        "id": "qcadfcHAWo_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gradient_penalty(model, real_images, fake_images):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    alpha = torch.randn((real_images.size(0), 1, 1, 1)).cuda()\n",
        "    interpolates = (alpha * real_images + ((1 - alpha) * fake_images)).requires_grad_(True)\n",
        "\n",
        "    model_interpolates = model(interpolates)\n",
        "    grad_outputs = torch.ones_like(model_interpolates, requires_grad=False).cuda()\n",
        "\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=model_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=grad_outputs,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)\n",
        "    return gradient_penalty"
      ],
      "metadata": {
        "id": "qJIShnggoy6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_channels, n_classes,size = 1, 1, 16\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "\n",
        "netD = Discriminator()\n",
        "netD.apply(weights_init)\n",
        "netD = netD.cuda()"
      ],
      "metadata": {
        "id": "7_VnWS14zIIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Proportion of rectangle in the image:\n",
        "lambda_rec = 0.00025\n",
        "\n",
        "# Fixing the seed for reproducibility:\n",
        "manualSeed = 1\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Number of parallel processes:\n",
        "workers = 2\n",
        "\n",
        "# Image size:\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels:\n",
        "nc = 1\n",
        "\n",
        "# Batch size:\n",
        "batch_size = 64\n",
        "\n",
        "# Number of batches per epoch (for the generator):\n",
        "num_batches_generator = 200\n",
        "num_epochs = 30\n",
        "\n",
        "# Learning rate:\n",
        "lr = 0.0001\n",
        "\n",
        "# Beta1 hyperparameter for Adam:\n",
        "beta1 = 0.  # In the paper introducing gradient penalty\n",
        "\n",
        "# Number of GPUs:\n",
        "ngpu = 1\n",
        "\n",
        "# Cross-entropy & label conventions:\n",
        "criterion = nn.BCELoss()\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Gradient penalty (gp) or classic WGAN:\n",
        "add_gp = True\n",
        "\n",
        "# Setup Adam optimizers for both G and D:\n",
        "# If gradient penalty:\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "# If not:\n",
        "# optimizerD = optim.RMSprop(netD.parameters(), lr=lr)\n",
        "# optimizerG = optim.RMSprop(netG.parameters(), lr=lr)\n",
        "\n",
        "# Schedulers:\n",
        "step_size = 31\n",
        "gamma = 0.2\n",
        "schedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=step_size, gamma=gamma)\n",
        "schedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=step_size, gamma=gamma)"
      ],
      "metadata": {
        "id": "Ml1gikCmxLNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To observe how G(z) evolves with fixed z during training:\n",
        "_ ,  fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "fixed_z = fixed_z.cuda()"
      ],
      "metadata": {
        "id": "2HOcNJdaV51G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "n_critic = 5\n",
        "clip = 0.01\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches_generator):\n",
        "        netG.train()\n",
        "        for j in range(n_critic):\n",
        "            x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "            netD.zero_grad()\n",
        "            real = x.cuda()\n",
        "            output_real = netD(real)\n",
        "            fake = netG(z.cuda())\n",
        "            output_fake = netD(fake.detach())\n",
        "\n",
        "            # Here, we limit the gradients of the discriminator:\n",
        "            if add_gp:\n",
        "                gradient_penalty = calculate_gradient_penalty(netD, real.data, fake.data)\n",
        "                errD = output_fake.mean() - output_real.mean() + 10 * gradient_penalty\n",
        "            else:\n",
        "                errD = output_fake.mean() - output_real.mean()\n",
        "\n",
        "            errD.backward()\n",
        "\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "            if not add_gp:\n",
        "                for p in netD.parameters():\n",
        "                    p.data.clamp_(-clip, clip)\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        fake = netG(z.cuda())\n",
        "        output_fake = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = -output_fake.mean()\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i, num_batches_generator,\n",
        "                     errD.item()))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "    with torch.no_grad():\n",
        "        netG.eval()\n",
        "        fake = netG(fixed_z.cuda()).detach().cpu()\n",
        "    img_list.append(fake)\n",
        "\n",
        "    schedulerD.step()\n",
        "    schedulerG.step()"
      ],
      "metadata": {
        "id": "4AUXImtWV1PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Can we still observe mode collapse in these images?"
      ],
      "metadata": {
        "id": "MFQetJ8E21xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "veHtXbinVpgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = plt.figure(1)\n",
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ],
      "metadata": {
        "id": "DbkFK-6cVms_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, the outputs of the generator, while not yet perfect, show no signs of mode collapse."
      ],
      "metadata": {
        "id": "PSH7BGAL-nUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Let's finally see the results of training over several hours. Load the UNet trained for 300 epochs (*netG_600.pt*) and visualize the generated images."
      ],
      "metadata": {
        "id": "U_8twouW-Yz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_channels, n_classes,size = 1, 1, 16\n",
        "netG_600ep = UNet(n_channels, n_classes, size).cuda()\n",
        "path_netG = \"Ex2_netG_600ep_WGP_lr0001.pt\"\n",
        "netG_600ep.load_state_dict(torch.load(path_netG)['model_state_dict'])\n",
        "netG_600ep = netG_600ep.cuda()"
      ],
      "metadata": {
        "id": "0QR9sW73QDkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netG_600ep.eval()\n",
        "\n",
        "\n",
        "x , z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "\n",
        "# Generate fake image batch with G\n",
        "\n",
        "\n",
        "real_and_fakes = [x]\n",
        "n = 4\n",
        "for i in range(n):\n",
        "    _ ,  z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "    z = z.cuda()\n",
        "    with torch.no_grad():\n",
        "        fake = netG_600ep(z).cpu()\n",
        "    real_and_fakes.append(fake)\n",
        "\n",
        "real_and_fakes = torch.cat(real_and_fakes,dim=0)\n",
        "fig1 = plt.figure(4, figsize=(36, 6))\n",
        "voir_batch2D(real_and_fakes, 6, fig1, k=0, min_scale=0, max_scale=1)"
      ],
      "metadata": {
        "id": "Mnrgyu5Hl6a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 5** Conditional GAN -> refer to exercise sheet #2."
      ],
      "metadata": {
        "id": "nxKXpYFWqML3"
      }
    }
  ]
}