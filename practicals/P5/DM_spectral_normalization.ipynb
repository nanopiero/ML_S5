{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSgiKnAs1BbN"
      },
      "source": [
        "# Spectral Normalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8IQ1Flnxj_Js"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "# import torch.nn.parallel\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rBewKJe7i4oa",
        "outputId": "0f84f4a4-6fa9-40d5-d22b-f1195abcb75f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ML_S5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/nanopiero/ML_S5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFNkLntQujEZ"
      },
      "source": [
        "Let's first define an image generation problem. The following function samples the random image $X$ and the random vector $Z$:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "id": "Ltxb1D0E7vfU",
        "outputId": "2a4c60d1-be6e-4f75-83c6-828f4c8167d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML_S5  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp ML_S5/practicals/P5/* .\n",
        "from utils_P5 import gen_DCGAN, voir_batch2D"
      ],
      "metadata": {
        "id": "avnSApzV1p_7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvM6l5tfG4cO"
      },
      "outputs": [],
      "source": [
        "# Rectangle proportion in the image:\n",
        "lambda_rec = 0.0\n",
        "\n",
        "x, z = gen_DCGAN(6, lambda_rec=lambda_rec)\n",
        "\n",
        "# Clean versions (individual cells)\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(x, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(z, 6, fig3, k=0, min_scale=0, max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKi_mw5LueFp"
      },
      "source": [
        "**Q1** Instanciate a UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5KtabSIMHVXi"
      },
      "outputs": [],
      "source": [
        "n_channels, n_classes, size = 1, 1, 16\n",
        "from utils_P5 import UNet\n",
        "netG = UNet(n_channels, n_classes, size).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MlYsVAtFDXi"
      },
      "source": [
        "**Q2** The Discriminator class is used to encode the discriminator. Instantiate it and use the *weight_init* function to initialize the network's weights. What type of network do you obtain in this way?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0wU8ftRHUSr"
      },
      "outputs": [],
      "source": [
        "ndf = 32\n",
        "nc = 1\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "netD = Discriminator().cuda()\n",
        "netD.apply(weights_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mSpp0qRw-TC"
      },
      "source": [
        "Let's now specify some training parameters (most of them are standard for GANs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cSzW08JSGbKU"
      },
      "outputs": [],
      "source": [
        "# Fixing the seed (to reproduce results)\n",
        "manualSeed = 1\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Number of parallel processes:\n",
        "workers = 2\n",
        "\n",
        "# Image size\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels\n",
        "nc = 1\n",
        "\n",
        "# Batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Number of batches per epoch\n",
        "num_batches = 200\n",
        "num_epochs = 64\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparameter for Adam\n",
        "beta1 = 0.5  # Sometimes simply 0.\n",
        "\n",
        "# Number of GPUs\n",
        "ngpu = 1\n",
        "\n",
        "# Cross-entropy\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Labels for real and fake images\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PKjdWbBBxedy"
      },
      "outputs": [],
      "source": [
        "# To observe how G(z) evolves with z fixed along the training:\n",
        "_ , fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "fixed_z = fixed_z.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gSP_UYGxokD"
      },
      "source": [
        "**Q3** Commenter le code ci-dessous après l'avoir lancé:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the convergence :\n",
        "def plot_PSD_and_Frechet_PSD(list_magnitude_spectrum):\n",
        "\n",
        "  # for magnitude_spectrum in list_magnitude_spectrum:\n",
        "  #   # Plot the mean_magnitude_spectrum\n",
        "  #   plt.imshow(magnitude_spectrum[0], cmap='gray', vmax=500)\n",
        "  #   plt.colorbar(label='Magnitude')\n",
        "  #   plt.title('Magnitude Spectrum (Adapted Intensity)')\n",
        "  #   plt.show()\n",
        "\n",
        "\n",
        "  for i, magnitude_spectrum in enumerate(list_magnitude_spectrum):\n",
        "    mean_magnitude_spectrum = magnitude_spectrum[0]\n",
        "    # Calculate the PSD (Power Spectral Density)\n",
        "    rows, cols = mean_magnitude_spectrum.shape[1:]\n",
        "    center_row, center_col = rows // 2, cols // 2\n",
        "    distances = torch.tensor([[((i - center_row)**2 + (j - center_col)**2)**0.5\n",
        "                              for j in range(cols)] for i in range(rows)])\n",
        "\n",
        "    radial_profile = []\n",
        "    for r in range(min(center_row, center_col)):\n",
        "        mask = (distances >= r) & (distances < r + 1)\n",
        "        values = mean_magnitude_spectrum[0, mask]\n",
        "        radial_profile.append(torch.mean(values).item())\n",
        "    # Plot the radially averaged spectrum\n",
        "    if i != 0:\n",
        "      col = [0,0,1-1/(i+2)]\n",
        "    else:\n",
        "      col = 'green'\n",
        "    plt.plot(radial_profile, color=col)\n",
        "\n",
        "    # plot sigma\n",
        "    std_magnitude_spectrum = magnitude_spectrum[1]\n",
        "    rows, cols = std_magnitude_spectrum.shape[1:]\n",
        "    center_row, center_col = rows // 2, cols // 2\n",
        "    distances = torch.tensor([[((i - center_row)**2 + (j - center_col)**2)**0.5\n",
        "                              for j in range(cols)] for i in range(rows)])\n",
        "\n",
        "    radial_profile = []\n",
        "    for r in range(min(center_row, center_col)):\n",
        "        mask = (distances >= r) & (distances < r + 1)\n",
        "        values = std_magnitude_spectrum[0, mask]\n",
        "        radial_profile.append(torch.mean(values).item())\n",
        "\n",
        "    # Plot the radially averaged spectrum\n",
        "    if i != 0:\n",
        "      col = [1-1/(i+2),0,0]\n",
        "    else:\n",
        "      col = 'yellow'\n",
        "    plt.plot(radial_profile, color=col)\n",
        "\n",
        "  plt.xlabel('Radial Distance from Center')\n",
        "  plt.ylabel('Average Magnitude')\n",
        "  plt.legend(['fake (av.)', 'fake (std)'] + ['real (av.)', 'real (std)'])\n",
        "  plt.yscale('log')\n",
        "  plt.title('Radially Averaged Fourier Spectrum (PSD)')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DVWJ2mp7WDbC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxWy6OkTzI5A"
      },
      "outputs": [],
      "source": [
        "# Lists for stats\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "list_mean_magnitude_spectrum_real = []\n",
        "list_std_magnitude_spectrum_real = []\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches):\n",
        "\n",
        "        # Sampling X and Z\n",
        "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "        # Real images\n",
        "        x = x.cuda()\n",
        "\n",
        "        # White noise\n",
        "        z = z.cuda()\n",
        "\n",
        "        # STEP 1: Discriminator optimization\n",
        "\n",
        "        # Zeroing discriminator gradients\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Discrimination of real images\n",
        "        D_real = netD(x).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of real images\n",
        "        b_size = x.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
        "        errD_real = criterion(D_real, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        # To calculate accuracy:\n",
        "        D_real = D_real.mean().item()\n",
        "\n",
        "        # Generated images\n",
        "        fake = netG(z.cuda())\n",
        "\n",
        "        # Discrimination of generated images\n",
        "        # .detach() -> we do not calculate gradients with respect to netG weights\n",
        "        # at this step\n",
        "        D_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of generated images\n",
        "        label.fill_(fake_label)\n",
        "        errD_fake = criterion(D_fake, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # Overall loss:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Update discriminator weights\n",
        "        optimizerD.step()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake = D_fake.mean().item()\n",
        "\n",
        "        # STEP 2: Generator optimization\n",
        "        netG.zero_grad()\n",
        "\n",
        "        # Regeneration, but gradients calculation is maintained\n",
        "        D_fake2 = netD(fake).view(-1)\n",
        "\n",
        "        # Update generator weights\n",
        "        label.fill_(real_label)\n",
        "        errG = criterion(D_fake2, label)\n",
        "        errG.backward()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake2 = D_fake2.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, num_batches,\n",
        "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "\n",
        "        # Store generated images from \"fixed_z\" every hundred epochs\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
        "            with torch.no_grad():\n",
        "                stored_fake = netG(fixed_z).detach().cpu()\n",
        "            img_list.append(stored_fake)\n",
        "        iters += 1\n",
        "\n",
        "        # add magnitude spectrum\n",
        "        with torch.no_grad():\n",
        "          try:\n",
        "            fftx = torch.abs(torch.fft.fft2(x))\n",
        "            fftfake = torch.abs(torch.fft.fft2(fake))\n",
        "            mean_magnitude_spectrum_real += fftx.sum(dim=0)\n",
        "            mean_magnitude_spectrum_fake += fftfake.sum(dim=0)\n",
        "            std_magnitude_spectrum_real += (fftx**2).sum(dim=0)\n",
        "            std_magnitude_spectrum_fake += (fftfake**2).sum(dim=0)\n",
        "\n",
        "\n",
        "          except:\n",
        "            print('init mean_magnitude_spectrum')\n",
        "            fftx = torch.fft.fft2(x)\n",
        "            fftfake = torch.fft.fft2(fake)\n",
        "            mean_magnitude_spectrum_real = fftx.sum(dim=0)\n",
        "            mean_magnitude_spectrum_fake = fftfake.sum(dim=0)\n",
        "            std_magnitude_spectrum_real = (fftx**2).sum(dim=0)\n",
        "            std_magnitude_spectrum_fake = (fftfake**2).sum(dim=0)\n",
        "\n",
        "\n",
        "    if epoch % 4 == 3: # last epoch before calculating mean (4 * 200 * 64 = 51200)\n",
        "      with torch.no_grad():\n",
        "        # get the mean\n",
        "        mean_magnitude_spectrum_real /= 4 * num_batches * batch_size\n",
        "        mean_magnitude_spectrum_fake /= 4 * num_batches * batch_size\n",
        "        std_magnitude_spectrum_real /= 4 * num_batches * batch_size\n",
        "        std_magnitude_spectrum_fake /= 4 * num_batches * batch_size\n",
        "        std_magnitude_spectrum_real -= mean_magnitude_spectrum_real**2\n",
        "        std_magnitude_spectrum_fake -= mean_magnitude_spectrum_fake**2\n",
        "        std_magnitude_spectrum_real = torch.sqrt(std_magnitude_spectrum_real)\n",
        "        std_magnitude_spectrum_fake = torch.sqrt(std_magnitude_spectrum_fake)\n",
        "\n",
        "        # Shift zero frequency to the center\n",
        "        mean_magnitude_spectrum_real = torch.fft.fftshift(mean_magnitude_spectrum_real)\n",
        "        mean_magnitude_spectrum_fake = torch.fft.fftshift(mean_magnitude_spectrum_fake)\n",
        "        std_magnitude_spectrum_real = torch.fft.fftshift(std_magnitude_spectrum_real)\n",
        "        std_magnitude_spectrum_fake = torch.fft.fftshift(std_magnitude_spectrum_fake)\n",
        "\n",
        "        # Calculate magnitude spectrum\n",
        "        list_mean_magnitude_spectrum_real.append((mean_magnitude_spectrum_real.cpu(),\n",
        "                                                  std_magnitude_spectrum_real.cpu()))\n",
        "\n",
        "        plot_PSD_and_Frechet_PSD(\n",
        "                                [(mean_magnitude_spectrum_fake.cpu(),\n",
        "                                  std_magnitude_spectrum_fake.cpu()\n",
        "                                  )] + list_mean_magnitude_spectrum_real)\n",
        "        del mean_magnitude_spectrum_real\n",
        "        del mean_magnitude_spectrum_fake\n",
        "        del std_magnitude_spectrum_real\n",
        "        del std_magnitude_spectrum_fake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBCnpIJFyIpz"
      },
      "source": [
        "**Q4** Plot the evolution of the cost functions for the generator and discriminator. Visualize the successive images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qStDjyBbHzK9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p6cQCvTIGKD"
      },
      "outputs": [],
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcyKBeWzIH5P"
      },
      "outputs": [],
      "source": [
        "# Testing the Generator:\n",
        "_ , z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "z = z.cuda()\n",
        "fake = netG(z).detach()\n",
        "\n",
        "fig = plt.figure(1, figsize=(12, 4))\n",
        "voir_batch2D(fake.cpu(), 14, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-0iCuAnOKh7"
      },
      "source": [
        "The training is not yet perfect (improvement could be achieved with more epochs), but the generator manages to sample images that are roughly close to the original images. It has started to reproduce intersections between cells. \\\n",
        "One could verify this quantitatively by comparing classical statistics (mean per pixel, standard deviation, etc.) or even spectral densities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsozbuqsyhnr"
      },
      "source": [
        "**Q5** Restart training with additional rectangles on the image. Visualize and comment on the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDrBZW-wME-x"
      },
      "outputs": [],
      "source": [
        "# Rectangle proportion in the image :\n",
        "lambda_rec = 0.00025\n",
        "\n",
        "x , z = gen_DCGAN(6,lambda_rec = lambda_rec)\n",
        "\n",
        "# Propre versions (only cells)\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(x, 6, fig1, k=0, min_scale=0,max_scale=1)\n",
        "\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(z, 6, fig3, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsD4m1ksLn9C"
      },
      "outputs": [],
      "source": [
        "manualSeed = 1\n",
        "num_epochs = 20\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "netD = Discriminator().cuda()\n",
        "netD.apply(weights_init)\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Lists for stats\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "list_mean_magnitude_spectrum_real = []\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches):\n",
        "        # Sampling X and Z\n",
        "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "        # Real images\n",
        "        x = x.cuda()\n",
        "\n",
        "        # White noise\n",
        "        z = z.cuda()\n",
        "\n",
        "        # STEP 1: Discriminator optimization\n",
        "\n",
        "        # Zeroing discriminator gradients\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Discrimination of real images\n",
        "        D_real = netD(x).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of real images\n",
        "        b_size = x.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
        "        errD_real = criterion(D_real, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        # To calculate accuracy:\n",
        "        D_real = D_real.mean().item()\n",
        "\n",
        "        # Generated images\n",
        "        fake = netG(z.cuda())\n",
        "\n",
        "        # Discrimination of generated images\n",
        "        # .detach() -> we do not calculate gradients with respect to netG weights\n",
        "        # at this step\n",
        "        D_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of generated images\n",
        "        label.fill_(fake_label)\n",
        "        errD_fake = criterion(D_fake, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # Overall loss:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Update discriminator weights\n",
        "        optimizerD.step()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake = D_fake.mean().item()\n",
        "\n",
        "        # STEP 2: Generator optimization\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "\n",
        "        # Regeneration, but gradients calculation is maintained\n",
        "        D_fake2 = netD(fake).view(-1)\n",
        "\n",
        "        # Update generator weights\n",
        "        errG = criterion(D_fake2, label)\n",
        "        errG.backward()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake2 = D_fake2.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, num_batches,\n",
        "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        try:\n",
        "          mean_magnitude_spectrum_real += torch.fft.fft2(x.sum(dim=0))\n",
        "          mean_magnitude_spectrum_fake += torch.fft.fft2(fake.sum(dim=0))\n",
        "        except:\n",
        "          print('init mean_magnitude_spectrum')\n",
        "          mean_magnitude_spectrum_real = torch.fft.fft2(x.sum(dim=0))\n",
        "          mean_magnitude_spectrum_fake = torch.fft.fft2(fake.sum(dim=0))\n",
        "\n",
        "\n",
        "        # Store generated images from \"fixed_z\" every hundred epochs\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_z.cuda()).detach().cpu()\n",
        "            img_list.append(fake)\n",
        "        iters += 1\n",
        "\n",
        "    if epoch % 4 == 3: # last epoch before calculating mean (4 * 200 * 64 = 51200)\n",
        "      # get the mean\n",
        "      mean_magnitude_spectrum_real /= 4 * num_batches * batch_size\n",
        "      mean_magnitude_spectrum_fake /= 4 * num_batches * batch_size\n",
        "\n",
        "      # Shift zero frequency to the center\n",
        "      mean_magnitude_spectrum_real = torch.fft.fftshift(mean_magnitude_spectrum_real)\n",
        "      mean_magnitude_spectrum_fake = torch.fft.fftshift(mean_magnitude_spectrum_fake)\n",
        "      # Calculate magnitude spectrum\n",
        "      mean_magnitude_spectrum_real = torch.abs(mean_magnitude_spectrum_real)\n",
        "      mean_magnitude_spectrum_fake = torch.abs(mean_magnitude_spectrum_fake)\n",
        "      list_mean_magnitude_spectrum_real.append(mean_magnitude_spectrum_real.cpu())\n",
        "      plot_mean_magnitude_spectrum_and_PSD(list_mean_magnitude_spectrum_real +\n",
        "                                          [mean_magnitude_spectrum_fake.cpu()])\n",
        "      del mean_magnitude_spectrum_real\n",
        "      del mean_magnitude_spectrum_fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtIKuBQfP5Li"
      },
      "outputs": [],
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-3], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNl_1vUXVZv0"
      },
      "source": [
        "On the generated images, a clear issue arises: the same rectangles reappear in multiple images of the batch. This problem is called 'mode collapse'. It often occurs with GANs and can complicate their training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7pVjRQIUCJY"
      },
      "source": [
        "**Exercise n°2** Wasserstein-GANs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIIq4Ypsyf2B"
      },
      "source": [
        "To facilitate the convergence of GANs, several approaches have been explored. In particular:\n",
        "- Giving the discriminator more time to converge at each step.\n",
        "- Keep the Lipschitzianity of the discriminator. This option takes its root in an interesting theoretical approach (see the supplementary exercise sheet). It can be done:\n",
        "\n",
        "  * by constraining the weights of the discriminator to remain within a given interval (see the paper introducing WGANs [(Wasserstein-GANs)](https://arxiv.org/abs/1701.07875).\n",
        "\n",
        "  * by [gradient penalization](https://arxiv.org/pdf/1704.00028.pdf)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUnziPsr3zO_"
      },
      "source": [
        "**Q2** In the following cells, these three approaches are coded. Say where."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcadfcHAWo_U"
      },
      "outputs": [],
      "source": [
        "nc = 1\n",
        "ndf = 32\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJIShnggoy6y"
      },
      "outputs": [],
      "source": [
        "def calculate_gradient_penalty(model, real_images, fake_images):\n",
        "    alpha = torch.randn((real_images.size(0), 1, 1, 1)).cuda()\n",
        "    interpolates = (alpha * real_images + ((1 - alpha) * fake_images)).requires_grad_(True)\n",
        "\n",
        "    model_interpolates = model(interpolates)\n",
        "    grad_outputs = torch.ones(model_interpolates.size(), requires_grad=False).cuda()\n",
        "\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=model_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=grad_outputs,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)\n",
        "    return gradient_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_VnWS14zIIZ"
      },
      "outputs": [],
      "source": [
        "n_channels, n_classes,size = 1, 1, 16\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "\n",
        "netD = Discriminator()\n",
        "netD.apply(weights_init)\n",
        "netD = netD.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml1gikCmxLNo"
      },
      "outputs": [],
      "source": [
        "# Proportion of rectangle in the image:\n",
        "lambda_rec = 0.00025\n",
        "\n",
        "# Fixing the seed for reproducibility:\n",
        "manualSeed = 1\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Number of parallel processes:\n",
        "workers = 2\n",
        "\n",
        "# Image size:\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels:\n",
        "nc = 1\n",
        "\n",
        "# Batch size:\n",
        "batch_size = 64\n",
        "\n",
        "# Number of batches per epoch (for the generator):\n",
        "num_batches_generator = 200\n",
        "num_epochs = 30\n",
        "\n",
        "# Learning rate:\n",
        "lr = 0.0001\n",
        "\n",
        "# Beta1 hyperparameter for Adam:\n",
        "beta1 = 0.  # In the paper introducing gradient penalty\n",
        "\n",
        "# Number of GPUs:\n",
        "ngpu = 1\n",
        "\n",
        "# Cross-entropy & label conventions:\n",
        "criterion = nn.BCELoss()\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Gradient penalty (gp) or classic WGAN:\n",
        "add_gp = True\n",
        "\n",
        "# Setup Adam optimizers for both G and D:\n",
        "# If gradient penalty:\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "# If not:\n",
        "# optimizerD = optim.RMSprop(netD.parameters(), lr=lr)\n",
        "# optimizerG = optim.RMSprop(netG.parameters(), lr=lr)\n",
        "\n",
        "# Schedulers:\n",
        "step_size = 31\n",
        "gamma = 0.2\n",
        "schedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=step_size, gamma=gamma)\n",
        "schedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=step_size, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HOcNJdaV51G"
      },
      "outputs": [],
      "source": [
        "# To observe how G(z) evolves with fixed z during training:\n",
        "_ ,  fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "fixed_z = fixed_z.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AUXImtWV1PN"
      },
      "outputs": [],
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "n_critic = 5\n",
        "clip = 0.01\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches_generator):\n",
        "        netG.train()\n",
        "        for j in range(n_critic):\n",
        "            x , z = gen_DCGAN(batch_size, lambda_rec = lambda_rec)\n",
        "\n",
        "\n",
        "            netD.zero_grad()\n",
        "            real = x.cuda()\n",
        "            output_real = netD(real)\n",
        "            fake = netG(z.cuda())\n",
        "            output_fake = netD(fake.detach())\n",
        "\n",
        "            # Ici, on limite les gradients du discriminateur:\n",
        "            if add_gp:\n",
        "                gradient_penalty = calculate_gradient_penalty(netD,\n",
        "                                                   real.data, fake.data)\n",
        "                errD = output_fake.mean() - output_real.mean() + 10 * gradient_penalty\n",
        "\n",
        "            else :\n",
        "                errD = output_fake.mean() - output_real.mean()\n",
        "\n",
        "            errD.backward()\n",
        "\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "            if not add_gp:\n",
        "                for p in netD.parameters():\n",
        "                    p.data.clamp_(-clip, clip)\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "#        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        fake = netG(z.cuda())\n",
        "        output_fake = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = - output_fake.mean()\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "#        D_G_z2 =  - output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
        "                  % (epoch+1, num_epochs, i, num_batches_generator,\n",
        "                     errD.item()))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "\n",
        "    with torch.no_grad():\n",
        "        netG.eval()\n",
        "        fake = netG(fixed_z.cuda()).detach().cpu()\n",
        "#            img_list.append(vutils.make_grid(fake, padding=2, normalize=False))\n",
        "    img_list.append(fake)\n",
        "\n",
        "\n",
        "    schedulerD.step()\n",
        "    schedulerG.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQetJ8E21xW"
      },
      "source": [
        "**Q3** Can we still observe mode collapse in these images?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veHtXbinVpgc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbkFK-6cVms_"
      },
      "outputs": [],
      "source": [
        "fig1 = plt.figure(1)\n",
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSH7BGAL-nUe"
      },
      "source": [
        "Indeed, the outputs of the generator, while not yet perfect, show no signs of mode collapse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_8twouW-Yz_"
      },
      "source": [
        "**Q4** Let's finally see the results of training over several hours. Load the UNet trained for 600 epochs (*netG_600.pt*) and visualize the generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QR9sW73QDkv"
      },
      "outputs": [],
      "source": [
        "n_channels, n_classes,size = 1, 1, 16\n",
        "netG_600ep = UNet(n_channels, n_classes, size).cuda()\n",
        "path_netG = \"Ex2_netG_600ep_WGP_lr0001.pt\"\n",
        "netG_600ep.load_state_dict(torch.load(path_netG)['model_state_dict'])\n",
        "netG_600ep = netG_600ep.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnrgyu5Hl6a4"
      },
      "outputs": [],
      "source": [
        "netG_600ep.eval()\n",
        "\n",
        "\n",
        "x , z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "\n",
        "# Generate fake image batch with G\n",
        "\n",
        "\n",
        "real_and_fakes = [x]\n",
        "n = 4\n",
        "for i in range(n):\n",
        "    _ ,  z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "    z = z.cuda()\n",
        "    with torch.no_grad():\n",
        "        fake = netG_600ep(z).cpu()\n",
        "    real_and_fakes.append(fake)\n",
        "\n",
        "real_and_fakes = torch.cat(real_and_fakes,dim=0)\n",
        "fig1 = plt.figure(4, figsize=(36, 6))\n",
        "voir_batch2D(real_and_fakes, 6, fig1, k=0, min_scale=0, max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ngoUG7xXz9y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice n°3** spectral normalization\n"
      ],
      "metadata": {
        "id": "U2mt8NpPz_uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils.spectral_norm as spectral_norm\n",
        "nc = 1\n",
        "ndf = 32\n",
        "\n",
        "class SDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SDiscriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), eps=1e-4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False), eps=1e-4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False), eps=1e-4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False), eps=1e-4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False), eps=1e-4),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "AO1psZlVSAQO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_P5 import gen_DCGAN, voir_batch2D\n",
        "# Rectangle proportion in the image :\n",
        "lambda_rec = 0.00025\n",
        "\n",
        "x, z = gen_DCGAN(6,lambda_rec = lambda_rec)\n",
        "\n",
        "# Propre versions (only cells)\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(x, 6, fig1, k=0, min_scale=0,max_scale=1)\n",
        "\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(z, 6, fig3, k=0, min_scale=0,max_scale=1)"
      ],
      "metadata": {
        "id": "zORflP0aCGP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To observe how G(z) evolves with z fixed along the training:\n",
        "_ , fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "fixed_z = fixed_z.cuda()"
      ],
      "metadata": {
        "id": "hJxIoeLTOu9u"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manualSeed = 1\n",
        "num_epochs = 64\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "netD = SDiscriminator().cuda()\n",
        "netD.apply(weights_init)\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Lists for stats\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "list_mean_magnitude_spectrum_real = []\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches):\n",
        "        # Sampling X and Z\n",
        "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "        # Real images\n",
        "        x = x.cuda()\n",
        "\n",
        "        # White noise\n",
        "        z = z.cuda()\n",
        "\n",
        "        # STEP 1: Discriminator optimization\n",
        "\n",
        "        # Zeroing discriminator gradients\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Discrimination of real images\n",
        "        D_real = netD(x).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of real images\n",
        "        b_size = x.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
        "        errD_real = criterion(D_real, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        # To calculate accuracy:\n",
        "        D_real = D_real.mean().item()\n",
        "\n",
        "        # Generated images\n",
        "        fake = netG(z.cuda())\n",
        "\n",
        "        # Discrimination of generated images\n",
        "        # .detach() -> we do not calculate gradients with respect to netG weights\n",
        "        # at this step\n",
        "        D_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of generated images\n",
        "        label.fill_(fake_label)\n",
        "        errD_fake = criterion(D_fake, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # Overall loss:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Update discriminator weights\n",
        "        optimizerD.step()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake = D_fake.mean().item()\n",
        "\n",
        "        # STEP 2: Generator optimization\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "\n",
        "        # Regeneration, but gradients calculation is maintained\n",
        "        D_fake2 = netD(fake).view(-1)\n",
        "\n",
        "        # Update generator weights\n",
        "        errG = criterion(D_fake2, label)\n",
        "        errG.backward()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake2 = D_fake2.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, num_batches,\n",
        "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        try:\n",
        "          mean_magnitude_spectrum_real += torch.fft.fft2(x.sum(dim=0))\n",
        "          mean_magnitude_spectrum_fake += torch.fft.fft2(fake.sum(dim=0))\n",
        "        except:\n",
        "          print('init mean_magnitude_spectrum')\n",
        "          mean_magnitude_spectrum_real = torch.fft.fft2(x.sum(dim=0))\n",
        "          mean_magnitude_spectrum_fake = torch.fft.fft2(fake.sum(dim=0))\n",
        "\n",
        "\n",
        "        # Store generated images from \"fixed_z\" every hundred epochs\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_z.cuda()).detach().cpu()\n",
        "            img_list.append(fake)\n",
        "        iters += 1\n",
        "\n",
        "    if epoch % 4 == 3: # last epoch before calculating mean (4 * 200 * 64 = 51200)\n",
        "      # get the mean\n",
        "      mean_magnitude_spectrum_real /= 4 * num_batches * batch_size\n",
        "      mean_magnitude_spectrum_fake /= 4 * num_batches * batch_size\n",
        "\n",
        "      # Shift zero frequency to the center\n",
        "      mean_magnitude_spectrum_real = torch.fft.fftshift(mean_magnitude_spectrum_real)\n",
        "      mean_magnitude_spectrum_fake = torch.fft.fftshift(mean_magnitude_spectrum_fake)\n",
        "      # Calculate magnitude spectrum\n",
        "      mean_magnitude_spectrum_real = torch.abs(mean_magnitude_spectrum_real)\n",
        "      mean_magnitude_spectrum_fake = torch.abs(mean_magnitude_spectrum_fake)\n",
        "      list_mean_magnitude_spectrum_real.append(mean_magnitude_spectrum_real.cpu())\n",
        "      plot_mean_magnitude_spectrum_and_PSD(list_mean_magnitude_spectrum_real +\n",
        "                                          [mean_magnitude_spectrum_fake.cpu()])\n",
        "      del mean_magnitude_spectrum_real\n",
        "      del mean_magnitude_spectrum_fake"
      ],
      "metadata": {
        "id": "sLaguua7AWbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-3], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ],
      "metadata": {
        "id": "fSeu4AwaMl3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blocs de base pour NowcastNet et DGMR"
      ],
      "metadata": {
        "id": "JlxeSVooARK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.spectral_norm as spectral_norm\n",
        "\n",
        "class GenBlock(nn.Module):\n",
        "    def __init__(self, fin, fout, opt, use_se=False, dilation=1, double_conv=False):\n",
        "        super().__init__()\n",
        "        self.learned_shortcut = (fin != fout)\n",
        "        fmiddle = min(fin, fout)\n",
        "        self.opt = opt\n",
        "        self.double_conv = double_conv\n",
        "\n",
        "        self.pad = nn.ReflectionPad2d(dilation)\n",
        "        self.conv_0 = nn.Conv2d(fin, fmiddle, kernel_size=3, padding=0, dilation=dilation)\n",
        "        self.conv_1 = nn.Conv2d(fmiddle, fout, kernel_size=3, padding=0, dilation=dilation)\n",
        "\n",
        "        if self.learned_shortcut:\n",
        "            self.conv_s = nn.Conv2d(fin, fout, kernel_size=1, bias=False)\n",
        "\n",
        "        self.conv_0 = spectral_norm(self.conv_0)\n",
        "        self.conv_1 = spectral_norm(self.conv_1)\n",
        "        if self.learned_shortcut:\n",
        "            self.conv_s = spectral_norm(self.conv_s)\n",
        "\n",
        "        ic = opt.evo_ic\n",
        "\n",
        "        self.norm_0 = SPADE(fin, ic)\n",
        "        self.norm_1 = SPADE(fmiddle, ic)\n",
        "        if self.learned_shortcut:\n",
        "            self.norm_s = SPADE(fin, ic)\n",
        "\n",
        "    def forward(self, x, evo):\n",
        "        x_s = self.shortcut(x, evo)\n",
        "        dx = self.conv_0(self.pad(self.actvn(self.norm_0(x, evo))))\n",
        "        if self.double_conv:\n",
        "            dx = self.conv_1(self.pad(self.actvn(self.norm_1(dx, evo))))\n",
        "\n",
        "        out = x_s + dx\n",
        "\n",
        "        return out\n",
        "\n",
        "    def shortcut(self, x, evo):\n",
        "        if self.learned_shortcut:\n",
        "            x_s = self.conv_s(self.norm_s(x, evo))\n",
        "        else:\n",
        "            x_s = x\n",
        "        return x_s\n",
        "\n",
        "    def actvn(self, x):\n",
        "        return F.leaky_relu(x, 2e-1)\n",
        "\n",
        "\n",
        "class SPADE(nn.Module):\n",
        "    def __init__(self, norm_nc, label_nc):\n",
        "        super().__init__()\n",
        "\n",
        "        ks = 3\n",
        "\n",
        "        self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=False)\n",
        "        nhidden = 64\n",
        "        ks = 3\n",
        "        pw = ks // 2\n",
        "        self.mlp_shared = nn.Sequential(\n",
        "            nn.ReflectionPad2d(pw),\n",
        "            nn.Conv2d(label_nc, nhidden, kernel_size=ks, padding=0),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.pad = nn.ReflectionPad2d(pw)\n",
        "        self.mlp_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=0)\n",
        "        self.mlp_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=0)\n",
        "\n",
        "    def forward(self, x, evo):\n",
        "\n",
        "        normalized = self.param_free_norm(x)\n",
        "        evo = F.adaptive_avg_pool2d(evo, output_size=x.size()[2:])\n",
        "\n",
        "        actv = self.mlp_shared(evo)\n",
        "\n",
        "        gamma = self.mlp_gamma(self.pad(actv))\n",
        "        beta = self.mlp_beta(self.pad(actv))\n",
        "\n",
        "        out = normalized * (1 + gamma) + beta\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "VsykLmmUt4_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import spectral_norm\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "\n",
        "    def   __init__(self, in_channels, out_channels, kernel=3, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            spectral_norm(nn.Conv2d(in_channels, mid_channels, kernel_size=kernel, padding=kernel//2)),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            spectral_norm(nn.Conv2d(mid_channels, out_channels, kernel_size=kernel, padding=kernel//2)),\n",
        "        )\n",
        "        self.single_conv = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=kernel, padding=kernel // 2))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = self.single_conv(x)\n",
        "        x = self.double_conv(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "class Down(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel=3):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels, kernel)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool_conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True, kernel=3):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, kernel=kernel, mid_channels=in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, kernel)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Up_S(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True, kernel=3):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, kernel=kernel, mid_channels=in_channels)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, kernel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "G0-YahblwW3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code from https://codeocean.com/capsule/3935105/tree/v1\n",
        "class Generative_Encoder(nn.Module):\n",
        "    def __init__(self, n_channels, base_c=64):\n",
        "        super(Generative_Encoder, self).__init__()\n",
        "        base_c = base_c\n",
        "        self.inc = DoubleConv(n_channels, base_c, kernel=3)\n",
        "        self.down1 = Down(base_c * 1, base_c * 2, 3)\n",
        "        self.down2 = Down(base_c * 2, base_c * 4, 3)\n",
        "        self.down3 = Down(base_c * 4, base_c * 8, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.inc(x)\n",
        "        x = self.down1(x)\n",
        "        x = self.down2(x)\n",
        "        x = self.down3(x)\n",
        "        return x\n",
        "\n",
        "class Generative_Decoder(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super().__init__()\n",
        "        self.opt = opt\n",
        "        nf = opt.ngf\n",
        "\n",
        "        ic = opt.ic_feature\n",
        "        self.fc = nn.Conv2d(ic, 8 * nf, 3, padding=1)\n",
        "\n",
        "        self.head_0 = GenBlock(8 * nf, 8 * nf, opt)\n",
        "\n",
        "        self.G_middle_0 = GenBlock(8 * nf, 4 * nf, opt, double_conv=True)\n",
        "        self.G_middle_1 = GenBlock(4 * nf, 4 * nf, opt, double_conv=True)\n",
        "\n",
        "        self.up_0 = GenBlock(4 * nf, 2 * nf, opt)\n",
        "\n",
        "        self.up_1 = GenBlock(2 * nf, 1 * nf, opt, double_conv=True)\n",
        "        self.up_2 = GenBlock(1 * nf, 1 * nf, opt, double_conv=True)\n",
        "\n",
        "        final_nc = nf * 1\n",
        "\n",
        "        self.conv_img = nn.Conv2d(final_nc, self.opt.gen_oc, 3, padding=1)\n",
        "        self.up = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x, evo):\n",
        "        x = self.fc(x)\n",
        "        x = self.head_0(x, evo)\n",
        "        x = self.up(x)\n",
        "        x = self.G_middle_0(x, evo)\n",
        "        x = self.G_middle_1(x, evo)\n",
        "        x = self.up(x)\n",
        "        x = self.up_0(x, evo)\n",
        "        x = self.up(x)\n",
        "        x = self.up_1(x, evo)\n",
        "        x = self.up_2(x, evo)\n",
        "        x = self.conv_img(F.leaky_relu(x, 2e-1))\n",
        "        return x\n",
        "\n",
        "# Discriminator\n",
        "class DBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(ProjBlock, self).__init__()\n",
        "        self.one_conv = spectral_norm(nn.Conv2d(in_channel, out_channel-in_channel, kernel_size=1, padding=0))\n",
        "        self.double_conv = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1)),\n",
        "            nn.ReLU(),\n",
        "            spectral_norm(nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = torch.cat([x, self.one_conv(x)], dim=1)\n",
        "        x2 = self.double_conv(x)\n",
        "        output = x1 + x2\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Bout de DGMR (même principe, mais en plus conv3D)\n",
        "# Ref : https://github.com/hyungting/DGMR-pytorch/blob/master/DGMR/dgmr_layers/DBlock.py\n",
        "\n",
        "\"\"\"\n",
        "Skilful precipitation nowcasting using deep generative models of radar, from DeepMind\n",
        "https://arxiv.org/abs/2104.00954\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "from .utils import Identity\n",
        "\n",
        "class DBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    D Block in https://arxiv.org/abs/2104.00954, downsampling 2-D convolution block.\n",
        "    Args:\n",
        "        in_channels: int, number of channels of input tensor.\n",
        "        out_channels: int, number of channels of output tensor.\n",
        "        relu: bool, whether to apply ReLU function.\n",
        "        downsample: bool, whether to apply scaling function.\n",
        "    Return:\n",
        "        torch.tensor\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels:int=None,\n",
        "        out_channels:int=None,\n",
        "        relu:bool=True,\n",
        "        downsample:bool=True\n",
        "        ):\n",
        "        super(DBlock, self).__init__()\n",
        "        Scaling = (nn.AvgPool2d(2, 2) if downsample else Identity())\n",
        "        ReLU = (nn.LeakyReLU(0.2) if relu else Identity()) #nn.ReLU() if relu else Identity())\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(in_channels, out_channels, 1, 1, 0), eps=1e-4),\n",
        "                Scaling\n",
        "                )\n",
        "        self.conv3x3 = nn.Sequential(\n",
        "                ReLU,\n",
        "                spectral_norm(nn.Conv2d(in_channels, in_channels, 3, 1, 1), eps=1e-4),\n",
        "                nn.LeakyReLU(0.2), #nn.ReLU(inplace=True),\n",
        "                spectral_norm(nn.Conv2d(in_channels, out_channels, 3, 1, 1), eps=1e-4),\n",
        "                Scaling\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1x1 = self.conv1x1(x)\n",
        "        conv3x3 = self.conv3x3(x)\n",
        "        return conv1x1 + conv3x3\n",
        "\n",
        "class D3Block(nn.Module):\n",
        "    \"\"\"\n",
        "    D Block in https://arxiv.org/abs/2104.00954, downsampling 3-D convolution block.\n",
        "    Args:\n",
        "        in_channels: int, number of channels of input tensor.\n",
        "        out_channels: int, number of channels of output tensor.\n",
        "        relu: bool, whether to apply ReLU function.\n",
        "        downsample: bool, whether to apply scaling function.\n",
        "    Return:\n",
        "        torch.tensor\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels:int=None,\n",
        "        out_channels:int=None,\n",
        "        relu:bool=True,\n",
        "        downsample:bool=True\n",
        "        ):\n",
        "        super(D3Block, self).__init__()\n",
        "        Scaling = (nn.AvgPool3d(2, 2) if downsample else Identity())\n",
        "        ReLU = (nn.LeakyReLU(0.2) if relu else Identity()) #nn.ReLU() if relu else Identity())\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv3d(in_channels, out_channels, 1, 1, \"same\"), eps=1e-4),\n",
        "                Scaling\n",
        "                )\n",
        "        self.conv3x3 = nn.Sequential(\n",
        "                ReLU,\n",
        "                spectral_norm(nn.Conv3d(in_channels, in_channels, 3, 1, \"same\"), eps=1e-4),\n",
        "                nn.LeakyReLU(0.2), #nn.ReLU(inplace=True),\n",
        "                spectral_norm(nn.Conv3d(in_channels, out_channels, 3, 1, \"same\"), eps=1e-4),\n",
        "                Scaling\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1x1 = self.conv1x1(x)\n",
        "        conv3x3 = self.conv3x3(x)\n",
        "        return conv1x1 + conv3x3\n",
        "\n",
        "\n",
        "\n",
        "# Bout DGMR :\n",
        "class SpatialDiscriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_frame: int=10,\n",
        "        debug: bool=False\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.n_frame = n_frame\n",
        "        self.debug = debug\n",
        "\n",
        "        self.avgpooling = nn.AvgPool2d(2)\n",
        "        self.d_blocks = nn.ModuleList([\n",
        "                DBlock(4, 48, relu=False, downsample=True), # 4 -> (3 * 4) * 4 = 48\n",
        "                DBlock(48, 96, downsample=True), # 48 -> (6 * 4) * 4 = 96\n",
        "                DBlock(96, 192, downsample=True), # 96 -> (12 * 4) * 4 = 192\n",
        "                DBlock(192, 384, downsample=True), # 192 -> (24 * 4) * 4 = 384\n",
        "                DBlock(384, 768, downsample=True), # 384 -> (48 * 4) * 4 = 768\n",
        "                DBlock(768, 768, downsample=False) # 768 -> 768, no downsample no * 4\n",
        "                ])\n",
        "        self.linear = nn.Sequential(\n",
        "                nn.BatchNorm1d(768),\n",
        "                spectral_norm(nn.Linear(768, 1))\n",
        "                )\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)\n",
        "        B, N, C, H, W = x.shape # batch_size, total_frames, channel=1, height, width\n",
        "        indices = random.sample(range(N), self.n_frame)\n",
        "        x = x[:, indices, :, :, :]\n",
        "        if self.debug: print(f\"Picked x: {x.shape}\")\n",
        "        x = x.view(B*self.n_frame, C, H, W)\n",
        "        if self.debug: print(f\"Reshaped: {x.shape}\")\n",
        "        x = self.avgpooling(x)\n",
        "        if self.debug: print(f\"Avg pool: {x.shape}\")\n",
        "        x = space2depth(x)\n",
        "        if self.debug: print(f\"S2Dshape: {x.shape}\")\n",
        "\n",
        "        for i, block in enumerate(self.d_blocks):\n",
        "            x = block(x)\n",
        "            if self.debug: print(f\"D block{i}: {x.shape}\")\n",
        "\n",
        "        # sum pooling\n",
        "        x = self.relu(x)\n",
        "        x = torch.sum(x, dim=(-1, -2))\n",
        "        if self.debug: print(f\"Sum pool: {x.shape}\")\n",
        "\n",
        "        x = self.linear(x)\n",
        "        if self.debug: print(f\"Linear : {x.shape}\")\n",
        "\n",
        "        x = x.view(B, self.n_frame, -1)\n",
        "        if self.debug: print(f\"Reshaped: {x.shape}\")\n",
        "\n",
        "        x = torch.sum(x, dim=1)\n",
        "        if self.debug: print(f\"Sum up : {x.shape}\")\n",
        "\n",
        "        return x\n",
        "\n",
        "class TemporalDiscriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        crop_size: int=256,\n",
        "        debug: bool=False\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.crop_size = crop_size\n",
        "        self.debug = debug\n",
        "\n",
        "        self.avgpooling = nn.AvgPool3d(2)\n",
        "        self.d3_blocks = nn.ModuleList([\n",
        "                D3Block(4, 48, relu=False, downsample=True), # C: 4 -> 48, T -> T/2\n",
        "                D3Block(48, 96, downsample=True) # C: 48 -> 96, T/2 -> T/4 (not exactly the same as DGMR)\n",
        "                ])\n",
        "        self.d_blocks = nn.ModuleList([\n",
        "                DBlock(96, 192, downsample=True), # 96 -> (12 * 4) * 4 = 192\n",
        "                DBlock(192, 384, downsample=True), # 192 -> (24 * 4) * 4 = 384\n",
        "                DBlock(384, 768, downsample=True), # 384 -> (48 * 4) * 4 = 768\n",
        "                DBlock(768, 768, downsample=False) # 768 -> 768, no downsample no * 4\n",
        "                ])\n",
        "        self.linear = nn.Sequential(\n",
        "                nn.BatchNorm1d(768),\n",
        "                spectral_norm(nn.Linear(768, 1))\n",
        "                )\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = random_crop(x, size=self.crop_size).to(x.device)\n",
        "        x = x.unsqueeze(1)\n",
        "        B, C, T, H, W = x.shape\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3, 4).view(B*T, C, H, W) # -> B, T, C, H, W\n",
        "        if self.debug: print(f\"Cropped : {x.shape}\")\n",
        "\n",
        "        x = space2depth(x) # B*T, C, H, W\n",
        "        x = x.view(B, T, -1, x.shape[-2], x.shape[-1]).permute(0, 2, 1, 3, 4) # -> B, C, T, H, W\n",
        "        if self.debug: print(f\"S2Dshape: {x.shape}\")\n",
        "\n",
        "        for i, block3d in enumerate(self.d3_blocks):\n",
        "            x = block3d(x)\n",
        "            if self.debug: print(f\"3D block: {x.shape}\")\n",
        "\n",
        "        B, C, T, H, W  = x.shape\n",
        "        x = x.permute(0, 2, 1, 3, 4).reshape(B*T, C, H, W)\n",
        "        if self.debug: print(f\"Reshaped: {x.shape}\")\n",
        "\n",
        "        for i, block in enumerate(self.d_blocks):\n",
        "            x = block(x)\n",
        "            if self.debug: print(f\"D block{i}: {x.shape}\")\n",
        "\n",
        "        # sum pooling\n",
        "        x = self.relu(x)\n",
        "        x = torch.sum(x, dim=(-1, -2))\n",
        "        if self.debug: print(f\"Sum pool: {x.shape}\")\n",
        "\n",
        "        x = self.linear(x)\n",
        "        if self.debug: print(f\"Linear : {x.shape}\")\n",
        "\n",
        "        x = x.view(B, T, -1)\n",
        "        if self.debug: print(f\"Reshaped: {x.shape}\")\n",
        "\n",
        "        x = torch.sum(x, dim=1)\n",
        "        if self.debug: print(f\"Sum up : {x.shape}\")\n",
        "\n",
        "        return x\n",
        "\n",
        "class DGMRDiscriminators(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_frame: int=10,\n",
        "        crop_size: int=128\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.spatial_discriminator = SpatialDiscriminator(n_frame=n_frame)\n",
        "        self.temporal_discriminator = TemporalDiscriminator(crop_size=crop_size)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        inputs = torch.cat((x, y), dim=1)\n",
        "        s_score = self.spatial_discriminator(inputs)\n",
        "        t_score = self.temporal_discriminator(inputs)\n",
        "        return torch.cat((s_score, t_score), dim=0)\n",
        "\n",
        "\n",
        "\n",
        "def space2depth(\n",
        "    x: torch.tensor=None,\n",
        "    factor: int=2\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Relocate pixels at (H, W) dimension to channel.\n",
        "    Args:\n",
        "        x: torch.tensor, tensor to be transformed.\n",
        "        factor: int, factor of size reduction.\n",
        "    \"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    x = nn.Unfold(factor, stride=factor)(x)\n",
        "    return x.view(B, C * factor ** 2, H // factor, W // factor)\n",
        "\n",
        "def depth2space(\n",
        "    x: torch.tensor=None,\n",
        "    factor: int=2\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Relocate pixels at channel to (H, W) dimension.\n",
        "    Args:\n",
        "        x: torch.tensor, tensor to be transformed.\n",
        "        factor: int, factor of size expansion.\n",
        "    \"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    x = x.view(B, C, H*W)\n",
        "    x = nn.Fold((H*factor, W*factor), kernel_size=(factor, factor), stride=factor)(x)\n",
        "    return x\n",
        "\n",
        "class Space2Depth(nn.Module):\n",
        "    \"\"\"\n",
        "    Relocate pixels at (H, W) dimension to channel.\n",
        "    See space2depth.\n",
        "    \"\"\"\n",
        "    def __init__(self, *args):\n",
        "        super(Space2Depth, self).__init__()\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) == 4:\n",
        "            return space2depth(x)\n",
        "        if len(x.shape) == 5:\n",
        "            B, C, T, H, W = x.shape\n",
        "            x = x.permute(0, 2, 1, 3, 4) # B, T, C, H, W\n",
        "            x = x.reshape(B*T, C, H, W)\n",
        "            x = space2depth(x)\n",
        "            x = x.view(B,  T, -1, x.shape[-2], x.shape[-1])\n",
        "            x = x.permute(0, 2, 1, 3, 4) # B, C, T, H, W\n",
        "            return x\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Identity, self).__init__()\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "def random_crop(x, size=128, padding=False):\n",
        "    B, C, H, W = x.shape\n",
        "    if padding:\n",
        "        # TODO: add padding=True method\n",
        "        pass\n",
        "    else:\n",
        "        h_idx = random.randint(0, H-size)\n",
        "        w_idx = random.randint(0, W-size)\n",
        "        x = x[:, :, h_idx:h_idx+size, w_idx:w_idx+size]\n",
        "    return x"
      ],
      "metadata": {
        "id": "tUedVsACu0To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxKXpYFWqML3"
      },
      "source": [
        "**Exercice n°4** A conditional GAN.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn-dvMLA_x3V"
      },
      "source": [
        "In this exercise, the goal is to implement a conditional Wasserstein-GAN. Once again, theoretical aspects are set aside; the objective is solely to construct the training loop.\n",
        "The context is as follows: we have a set of images representing a domain 𝒟.\n",
        "The traditional GAN generates new images from 𝒟. In this exercise, we will generate images compatible with a given list of pixel values a priori.\n",
        "\n",
        "The following cells allow visualization of the available dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQEBbOQq_xCz"
      },
      "outputs": [],
      "source": [
        "# Proportion of pixels preserved in yi:\n",
        "obs_density = 0.005\n",
        "\n",
        "x, y, z = gen_condDCGAN(6, obs_density)\n",
        "\n",
        "# Full images xi\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "visualize_2D_batch(x, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Fragmentary images yi: a few pixels randomly sampled from xi\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "visualize_2D_batch(y, 6, fig2, k=0, min_scale=-0.2, max_scale=1)\n",
        "\n",
        "# zi: sample from a centered reduced Gaussian vector\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "visualize_2D_batch(z, 6, fig3, k=0, min_scale=0, max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bOzh1IW_-ud"
      },
      "source": [
        "**Q1** Drawing inspiration from the previous exercise, complete the training loop and run it for ten epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtK8wz6iARji"
      },
      "outputs": [],
      "source": [
        "# SGD Setup\n",
        "batch_size = 128\n",
        "num_batches_generator = 200\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "# Optimizer Parameters\n",
        "lr = 0.0005\n",
        "beta1 = 0.  # SGD momentum\n",
        "\n",
        "# nn setup\n",
        "ndf = 32\n",
        "n_channels = 2\n",
        "n_classes = 1\n",
        "size = 16\n",
        "\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "netD = Discriminator(n_channels).cuda()\n",
        "\n",
        "# optimizers\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQX7RyRrAWPj"
      },
      "outputs": [],
      "source": [
        "real_label = 1.\n",
        "fake_label = 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klbcqnE8AYm7"
      },
      "outputs": [],
      "source": [
        "# To keep track of generated images from a fixed sample of $z_i$:\n",
        "fixed_x, fixed_y, fixed_z = gen_condDCGAN(8, p=dens_obs)\n",
        "\n",
        "# Fixed input for the generator:\n",
        "fixed_yz = torch.cat((fixed_y, fixed_z), dim=1).cuda()\n",
        "\n",
        "# Lists\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "# Other hyperparameters\n",
        "n_critic = 5\n",
        "clip = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1-D_aF-AcCj"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i in range(num_batches_generator):\n",
        "\n",
        "        ############################\n",
        "        # (1) Maximization of log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        netG.train()\n",
        "        # Here, we perform multiple (n_critic) optimization steps for the discriminator.\n",
        "        for j in range(n_critic):\n",
        "\n",
        "            x, y, z = gen_condDCGAN(batch_size, p=dens_obs)\n",
        "\n",
        "            # Move to GPU\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "            z = z.cuda()\n",
        "\n",
        "            # Concatenations:\n",
        "            xy = torch.cat((x, y))\n",
        "            yz = torch.cat((y, z))\n",
        "\n",
        "            output_xy = netD(xy)\n",
        "\n",
        "            fake = netG(yz)\n",
        "            fake = fake.detach()\n",
        "\n",
        "            fakey = torch.cat((fake, y), dim=1)\n",
        "            output_fakey = netD(fakey)\n",
        "\n",
        "            # Regularization by gradient penalty\n",
        "            gradient_penalty = calculate_gradient_penalty(netD, xy.data, fakey.data)\n",
        "\n",
        "            # Calculate discriminator error and update gradients:\n",
        "            label = torch.full((xy.size(0),), real_label, dtype=torch.float).cuda()\n",
        "            err_D_real = criterion(output_xy.view(-1), label)\n",
        "            errD_real.backward()\n",
        "            label.fill_(fake_label)\n",
        "            errD_fake = criterion(output_fakey, label)\n",
        "            errD_fake.backward()\n",
        "\n",
        "            errD = err_D_real + errD_fake  # In case we want to store it later\n",
        "\n",
        "            optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # Maximization of log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "\n",
        "        fake = netD(fake).view(-1)\n",
        "        fakey = torch.cat((fake, y), dim=1)\n",
        "\n",
        "        output_fakey = netD(fakey)\n",
        "\n",
        "        errG = -output_fakey.mean()\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i, num_batches_generator,\n",
        "                     errD.item()))\n",
        "\n",
        "        # Record losses\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(-errD.item())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        netG.eval()\n",
        "        fake = netG(fixed_yz.cuda()).detach().cpu()\n",
        "\n",
        "    img_list.append(fake)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7jeF2FAjDC"
      },
      "source": [
        "**Q2** Visualize some images and comment on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRxifP75AgQM"
      },
      "outputs": [],
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1QHK-AGApMr"
      },
      "source": [
        "**Q3** To obtain a GAN that takes into account the condition contained in $y_i$, it is necessary to push the training further. The file *netG_180ep_WGP_scheduler75_lr005.pt* contains the weights obtained after training for 300 epochs. Load these weights and visualize several images for the same inputs $x_i$ and $z_i$. Check the coherence and draw conclusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH81OZsMAot9"
      },
      "outputs": [],
      "source": [
        "weights = torch.load('netG_180ep_WGP_scheduler75_lr005.pt')\n",
        "netG = UNet(2, 1, 16).cuda()\n",
        "netG.load_state_dict(weights['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73UgleVAyXb"
      },
      "outputs": [],
      "source": [
        "netG.eval()\n",
        "\n",
        "x , y , z = gen_condDCGAN(6, p = dens_obs)\n",
        "\n",
        "xy = torch.cat((x,y))\n",
        "real_and_fakes = [xy]\n",
        "n=6\n",
        "for i in range(n):\n",
        "    _ , y , z = gen_condDCGAN(6, p = dens_obs)\n",
        "    y = y.cuda()\n",
        "    z = z.cuda()\n",
        "    yz = torch.cat((y,z),dim=1)\n",
        "    with torch.no_grad():\n",
        "      fake = netG(yz).cpu()\n",
        "    real_and_fakes.append(fake)\n",
        "\n",
        "real_and_fakes = torch.cat(real_and_fakes,dim=0)\n",
        "fig1 = plt.figure(4, figsize=(36, 6))\n",
        "voir_batch2D(real_and_fakes, 6, fig1, k=0, min_scale=0, max_scale=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}