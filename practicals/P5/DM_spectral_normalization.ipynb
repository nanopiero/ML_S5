{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSgiKnAs1BbN"
      },
      "source": [
        "# Spectral Normalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "8IQ1Flnxj_Js"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "# import torch.nn.parallel\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rBewKJe7i4oa",
        "outputId": "50cae996-ddbf-447a-8647-08136901dc62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML_S5'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 103 (delta 24), reused 76 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (103/103), 37.05 MiB | 16.58 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/nanopiero/ML_S5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFNkLntQujEZ"
      },
      "source": [
        "Let's first define an image generation problem. The following function samples the random image $X$ and the random vector $Z$:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "id": "Ltxb1D0E7vfU",
        "outputId": "0030639e-06d0-48a7-f932-d980fbbef339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML_S5  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp ML_S5/practicals/P5/* .\n",
        "from utils_P5 import gen_DCGAN, voir_batch2D"
      ],
      "metadata": {
        "id": "avnSApzV1p_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvM6l5tfG4cO"
      },
      "outputs": [],
      "source": [
        "# Rectangle proportion in the image:\n",
        "lambda_rec = 0.0\n",
        "\n",
        "x, z = gen_DCGAN(6, lambda_rec=lambda_rec)\n",
        "\n",
        "# Clean versions (individual cells)\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(x, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(z, 6, fig3, k=0, min_scale=0, max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKi_mw5LueFp"
      },
      "source": [
        "**Q1** Instanciate a UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "5KtabSIMHVXi"
      },
      "outputs": [],
      "source": [
        "n_channels, n_classes, size = 1, 1, 16\n",
        "from utils_P5 import UNet\n",
        "netG = UNet(n_channels, n_classes, size).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MlYsVAtFDXi"
      },
      "source": [
        "**Q2** The Discriminator class is used to encode the discriminator. Instantiate it and use the *weight_init* function to initialize the network's weights. What type of network do you obtain in this way?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0wU8ftRHUSr"
      },
      "outputs": [],
      "source": [
        "ndf = 32\n",
        "nc = 1\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "netD = Discriminator().cuda()\n",
        "netD.apply(weights_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mSpp0qRw-TC"
      },
      "source": [
        "Let's now specify some training parameters (most of them are standard for GANs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "cSzW08JSGbKU"
      },
      "outputs": [],
      "source": [
        "# Fixing the seed (to reproduce results)\n",
        "manualSeed = 1\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Number of parallel processes:\n",
        "workers = 2\n",
        "\n",
        "# Image size\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels\n",
        "nc = 1\n",
        "\n",
        "# Batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Number of batches per epoch\n",
        "num_batches = 200\n",
        "num_epochs = 64\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparameter for Adam\n",
        "beta1 = 0.5  # Sometimes simply 0.\n",
        "\n",
        "# Number of GPUs\n",
        "ngpu = 1\n",
        "\n",
        "# Cross-entropy\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Labels for real and fake images\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "PKjdWbBBxedy"
      },
      "outputs": [],
      "source": [
        "# To observe how G(z) evolves with z fixed along the training:\n",
        "_ , fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "fixed_z = fixed_z.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gSP_UYGxokD"
      },
      "source": [
        "**Q3** Commenter le code ci-dessous apr√®s l'avoir lanc√©:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the convergence :\n",
        "def plot_mean_magnitude_spectrum_and_PSD(list_magnitude_spectrum):\n",
        "\n",
        "  # for magnitude_spectrum in list_magnitude_spectrum:\n",
        "  #   # Plot the mean_magnitude_spectrum\n",
        "  #   plt.imshow(magnitude_spectrum[0], cmap='gray', vmax=500)\n",
        "  #   plt.colorbar(label='Magnitude')\n",
        "  #   plt.title('Magnitude Spectrum (Adapted Intensity)')\n",
        "  #   plt.show()\n",
        "\n",
        "\n",
        "  for i, magnitude_spectrum in enumerate(list_magnitude_spectrum):\n",
        "    # Calculate the PSD (Power Spectral Density)\n",
        "    rows, cols = magnitude_spectrum.shape[1:]\n",
        "    center_row, center_col = rows // 2, cols // 2\n",
        "    distances = torch.tensor([[((i - center_row)**2 + (j - center_col)**2)**0.5\n",
        "                              for j in range(cols)] for i in range(rows)])\n",
        "\n",
        "    radial_profile = []\n",
        "    for r in range(min(center_row, center_col)):\n",
        "        mask = (distances >= r) & (distances < r + 1)\n",
        "        values = magnitude_spectrum[0, mask]\n",
        "        radial_profile.append(torch.mean(values).item())\n",
        "\n",
        "\n",
        "    # Plot the radially averaged spectrum\n",
        "    if i != len(list_magnitude_spectrum) - 1:\n",
        "      col = [0,0,1-1/(i+1)]\n",
        "    else:\n",
        "      col = 'red'\n",
        "    plt.plot(radial_profile, color=col)\n",
        "\n",
        "  plt.xlabel('Radial Distance from Center')\n",
        "  plt.ylabel('Average Magnitude')\n",
        "  plt.legend((len(list_magnitude_spectrum) -1 ) * ['real'] + ['fake'])\n",
        "  plt.yscale('log')\n",
        "  plt.title('Radially Averaged Fourier Spectrum (PSD)')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DVWJ2mp7WDbC"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxWy6OkTzI5A"
      },
      "outputs": [],
      "source": [
        "# Lists for stats\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "list_mean_magnitude_spectrum_real = []\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches):\n",
        "\n",
        "        # Sampling X and Z\n",
        "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "        # Real images\n",
        "        x = x.cuda()\n",
        "\n",
        "        # White noise\n",
        "        z = z.cuda()\n",
        "\n",
        "        # STEP 1: Discriminator optimization\n",
        "\n",
        "        # Zeroing discriminator gradients\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Discrimination of real images\n",
        "        D_real = netD(x).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of real images\n",
        "        b_size = x.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
        "        errD_real = criterion(D_real, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        # To calculate accuracy:\n",
        "        D_real = D_real.mean().item()\n",
        "\n",
        "        # Generated images\n",
        "        fake = netG(z.cuda())\n",
        "\n",
        "        # Discrimination of generated images\n",
        "        # .detach() -> we do not calculate gradients with respect to netG weights\n",
        "        # at this step\n",
        "        D_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of generated images\n",
        "        label.fill_(fake_label)\n",
        "        errD_fake = criterion(D_fake, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # Overall loss:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Update discriminator weights\n",
        "        optimizerD.step()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake = D_fake.mean().item()\n",
        "\n",
        "        # STEP 2: Generator optimization\n",
        "        netG.zero_grad()\n",
        "\n",
        "        # Regeneration, but gradients calculation is maintained\n",
        "        D_fake2 = netD(fake).view(-1)\n",
        "\n",
        "        # Update generator weights\n",
        "        label.fill_(real_label)\n",
        "        errG = criterion(D_fake2, label)\n",
        "        errG.backward()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake2 = D_fake2.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, num_batches,\n",
        "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # add magnitude spectrum\n",
        "        try:\n",
        "          mean_magnitude_spectrum_real += torch.fft.fft2(x.sum(dim=0))\n",
        "          mean_magnitude_spectrum_fake += torch.fft.fft2(fake.sum(dim=0))\n",
        "        except:\n",
        "          print('init mean_magnitude_spectrum')\n",
        "          mean_magnitude_spectrum_real = torch.fft.fft2(x.sum(dim=0))\n",
        "          mean_magnitude_spectrum_fake = torch.fft.fft2(fake.sum(dim=0))\n",
        "\n",
        "        # Store generated images from \"fixed_z\" every hundred epochs\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
        "            with torch.no_grad():\n",
        "                stored_fake = netG(fixed_z).detach().cpu()\n",
        "            img_list.append(stored_fake)\n",
        "        iters += 1\n",
        "\n",
        "    if epoch % 4 == 3: # last epoch before calculating mean (4 * 200 * 64 = 51200)\n",
        "      # get the mean\n",
        "      mean_magnitude_spectrum_real /= 4 * num_batches * batch_size\n",
        "      mean_magnitude_spectrum_fake /= 4 * num_batches * batch_size\n",
        "\n",
        "      # Shift zero frequency to the center\n",
        "      mean_magnitude_spectrum_real = torch.fft.fftshift(mean_magnitude_spectrum_real)\n",
        "      mean_magnitude_spectrum_fake = torch.fft.fftshift(mean_magnitude_spectrum_fake)\n",
        "      # Calculate magnitude spectrum\n",
        "      mean_magnitude_spectrum_real = torch.abs(mean_magnitude_spectrum_real)\n",
        "      mean_magnitude_spectrum_fake = torch.abs(mean_magnitude_spectrum_fake)\n",
        "      list_mean_magnitude_spectrum_real.append(mean_magnitude_spectrum_real.cpu())\n",
        "      plot_mean_magnitude_spectrum_and_PSD(list_mean_magnitude_spectrum_real +\n",
        "                                          [mean_magnitude_spectrum_fake.cpu()])\n",
        "      del mean_magnitude_spectrum_real\n",
        "      del mean_magnitude_spectrum_fake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "      del mean_magnitude_spectrum_real\n",
        "      del mean_magnitude_spectrum_fake"
      ],
      "metadata": {
        "id": "rBVTSp0vY3tp"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_magnitude_spectrum_real.cpu().squeeze(0).shape"
      ],
      "metadata": {
        "id": "yc3AcvftU_FR",
        "outputId": "96314a72-d8ed-4024-ae12-aac296ff25d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwcmQm7mOCsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBCnpIJFyIpz"
      },
      "source": [
        "**Q4** Plot the evolution of the cost functions for the generator and discriminator. Visualize the successive images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qStDjyBbHzK9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p6cQCvTIGKD"
      },
      "outputs": [],
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcyKBeWzIH5P"
      },
      "outputs": [],
      "source": [
        "# Testing the Generator:\n",
        "_ , z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "z = z.cuda()\n",
        "fake = netG(z).detach()\n",
        "\n",
        "fig = plt.figure(1, figsize=(12, 4))\n",
        "voir_batch2D(fake.cpu(), 14, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-0iCuAnOKh7"
      },
      "source": [
        "The training is not yet perfect (improvement could be achieved with more epochs), but the generator manages to sample images that are roughly close to the original images. It has started to reproduce intersections between cells. \\\n",
        "One could verify this quantitatively by comparing classical statistics (mean per pixel, standard deviation, etc.) or even spectral densities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsozbuqsyhnr"
      },
      "source": [
        "**Q5** Restart training with additional rectangles on the image. Visualize and comment on the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDrBZW-wME-x"
      },
      "outputs": [],
      "source": [
        "# Rectangle proportion in the image :\n",
        "lambda_rec = 0.00025\n",
        "\n",
        "x , z = gen_DCGAN(6,lambda_rec = lambda_rec)\n",
        "\n",
        "# Propre versions (only cells)\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(x, 6, fig1, k=0, min_scale=0,max_scale=1)\n",
        "\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(z, 6, fig3, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsD4m1ksLn9C"
      },
      "outputs": [],
      "source": [
        "manualSeed = 1\n",
        "num_epochs = 20\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "netD = Discriminator().cuda()\n",
        "netD.apply(weights_init)\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Lists for stats\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches):\n",
        "        # Sampling X and Z\n",
        "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "\n",
        "        # Real images\n",
        "        x = x.cuda()\n",
        "\n",
        "        # White noise\n",
        "        z = z.cuda()\n",
        "\n",
        "        # STEP 1: Discriminator optimization\n",
        "\n",
        "        # Zeroing discriminator gradients\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # Discrimination of real images\n",
        "        D_real = netD(x).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of real images\n",
        "        b_size = x.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
        "        errD_real = criterion(D_real, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        # To calculate accuracy:\n",
        "        D_real = D_real.mean().item()\n",
        "\n",
        "        # Generated images\n",
        "        fake = netG(z.cuda())\n",
        "\n",
        "        # Discrimination of generated images\n",
        "        # .detach() -> we do not calculate gradients with respect to netG weights\n",
        "        # at this step\n",
        "        D_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Gradients with respect to discriminator weights on the batch of generated images\n",
        "        label.fill_(fake_label)\n",
        "        errD_fake = criterion(D_fake, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # Overall loss:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Update discriminator weights\n",
        "        optimizerD.step()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake = D_fake.mean().item()\n",
        "\n",
        "        # STEP 2: Generator optimization\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "\n",
        "        # Regeneration, but gradients calculation is maintained\n",
        "        D_fake2 = netD(fake).view(-1)\n",
        "\n",
        "        # Update generator weights\n",
        "        errG = criterion(D_fake2, label)\n",
        "        errG.backward()\n",
        "\n",
        "        # To display accuracy\n",
        "        D_fake2 = D_fake2.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, num_batches,\n",
        "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Store generated images from \"fixed_z\" every hundred epochs\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_z.cuda()).detach().cpu()\n",
        "            img_list.append(fake)\n",
        "        iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtIKuBQfP5Li"
      },
      "outputs": [],
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNl_1vUXVZv0"
      },
      "source": [
        "SOn the generated images, a clear issue arises: the same rectangles reappear in multiple images of the batch. This problem is called 'mode collapse'. It often occurs with GANs and can complicate their training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7pVjRQIUCJY"
      },
      "source": [
        "**Exercise n¬∞2** Wasserstein-GANs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIIq4Ypsyf2B"
      },
      "source": [
        "To facilitate the convergence of GANs, several approaches have been explored. In particular:\n",
        "- Giving the discriminator more time to converge at each step.\n",
        "- Keep the Lipschitzianity of the discriminator. This option takes its root in an interesting theoretical approach (see the supplementary exercise sheet). It can be done:\n",
        "\n",
        "  * by constraining the weights of the discriminator to remain within a given interval (see the paper introducing WGANs [(Wasserstein-GANs)](https://arxiv.org/abs/1701.07875).\n",
        "\n",
        "  * by [gradient penalization](https://arxiv.org/pdf/1704.00028.pdf)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUnziPsr3zO_"
      },
      "source": [
        "**Q2** In the following cells, these three approaches are coded. Say where."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcadfcHAWo_U"
      },
      "outputs": [],
      "source": [
        "nc = 1\n",
        "ndf = 32\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJIShnggoy6y"
      },
      "outputs": [],
      "source": [
        "def calculate_gradient_penalty(model, real_images, fake_images):\n",
        "    alpha = torch.randn((real_images.size(0), 1, 1, 1)).cuda()\n",
        "    interpolates = (alpha * real_images + ((1 - alpha) * fake_images)).requires_grad_(True)\n",
        "\n",
        "    model_interpolates = model(interpolates)\n",
        "    grad_outputs = torch.ones(model_interpolates.size(), requires_grad=False).cuda()\n",
        "\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=model_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=grad_outputs,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)\n",
        "    return gradient_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_VnWS14zIIZ"
      },
      "outputs": [],
      "source": [
        "n_channels, n_classes,size = 1, 1, 16\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "\n",
        "netD = Discriminator()\n",
        "netD.apply(weights_init)\n",
        "netD = netD.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml1gikCmxLNo"
      },
      "outputs": [],
      "source": [
        "# Proportion of rectangle in the image:\n",
        "lambda_rec = 0.00025\n",
        "\n",
        "# Fixing the seed for reproducibility:\n",
        "manualSeed = 1\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Number of parallel processes:\n",
        "workers = 2\n",
        "\n",
        "# Image size:\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels:\n",
        "nc = 1\n",
        "\n",
        "# Batch size:\n",
        "batch_size = 64\n",
        "\n",
        "# Number of batches per epoch (for the generator):\n",
        "num_batches_generator = 200\n",
        "num_epochs = 30\n",
        "\n",
        "# Learning rate:\n",
        "lr = 0.0001\n",
        "\n",
        "# Beta1 hyperparameter for Adam:\n",
        "beta1 = 0.  # In the paper introducing gradient penalty\n",
        "\n",
        "# Number of GPUs:\n",
        "ngpu = 1\n",
        "\n",
        "# Cross-entropy & label conventions:\n",
        "criterion = nn.BCELoss()\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Gradient penalty (gp) or classic WGAN:\n",
        "add_gp = True\n",
        "\n",
        "# Setup Adam optimizers for both G and D:\n",
        "# If gradient penalty:\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "# If not:\n",
        "# optimizerD = optim.RMSprop(netD.parameters(), lr=lr)\n",
        "# optimizerG = optim.RMSprop(netG.parameters(), lr=lr)\n",
        "\n",
        "# Schedulers:\n",
        "step_size = 31\n",
        "gamma = 0.2\n",
        "schedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=step_size, gamma=gamma)\n",
        "schedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=step_size, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HOcNJdaV51G"
      },
      "outputs": [],
      "source": [
        "# To observe how G(z) evolves with fixed z during training:\n",
        "_ ,  fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
        "fixed_z = fixed_z.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AUXImtWV1PN"
      },
      "outputs": [],
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "n_critic = 5\n",
        "clip = 0.01\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_batches_generator):\n",
        "        netG.train()\n",
        "        for j in range(n_critic):\n",
        "            x , z = gen_DCGAN(batch_size, lambda_rec = lambda_rec)\n",
        "\n",
        "\n",
        "            netD.zero_grad()\n",
        "            real = x.cuda()\n",
        "            output_real = netD(real)\n",
        "            fake = netG(z.cuda())\n",
        "            output_fake = netD(fake.detach())\n",
        "\n",
        "            # Ici, on limite les gradients du discriminateur:\n",
        "            if add_gp:\n",
        "                gradient_penalty = calculate_gradient_penalty(netD,\n",
        "                                                   real.data, fake.data)\n",
        "                errD = output_fake.mean() - output_real.mean() + 10 * gradient_penalty\n",
        "\n",
        "            else :\n",
        "                errD = output_fake.mean() - output_real.mean()\n",
        "\n",
        "            errD.backward()\n",
        "\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "            if not add_gp:\n",
        "                for p in netD.parameters():\n",
        "                    p.data.clamp_(-clip, clip)\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "#        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        fake = netG(z.cuda())\n",
        "        output_fake = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = - output_fake.mean()\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "#        D_G_z2 =  - output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
        "                  % (epoch+1, num_epochs, i, num_batches_generator,\n",
        "                     errD.item()))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "\n",
        "    with torch.no_grad():\n",
        "        netG.eval()\n",
        "        fake = netG(fixed_z.cuda()).detach().cpu()\n",
        "#            img_list.append(vutils.make_grid(fake, padding=2, normalize=False))\n",
        "    img_list.append(fake)\n",
        "\n",
        "\n",
        "    schedulerD.step()\n",
        "    schedulerG.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQetJ8E21xW"
      },
      "source": [
        "**Q3** Can we still observe mode collapse in these images?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veHtXbinVpgc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbkFK-6cVms_"
      },
      "outputs": [],
      "source": [
        "fig1 = plt.figure(1)\n",
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSH7BGAL-nUe"
      },
      "source": [
        "Indeed, the outputs of the generator, while not yet perfect, show no signs of mode collapse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_8twouW-Yz_"
      },
      "source": [
        "**Q4** Let's finally see the results of training over several hours. Load the UNet trained for 600 epochs (*netG_600.pt*) and visualize the generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QR9sW73QDkv"
      },
      "outputs": [],
      "source": [
        "n_channels, n_classes,size = 1, 1, 16\n",
        "netG_600ep = UNet(n_channels, n_classes, size).cuda()\n",
        "path_netG = \"Ex2_netG_600ep_WGP_lr0001.pt\"\n",
        "netG_600ep.load_state_dict(torch.load(path_netG)['model_state_dict'])\n",
        "netG_600ep = netG_600ep.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnrgyu5Hl6a4"
      },
      "outputs": [],
      "source": [
        "netG_600ep.eval()\n",
        "\n",
        "\n",
        "x , z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "\n",
        "# Generate fake image batch with G\n",
        "\n",
        "\n",
        "real_and_fakes = [x]\n",
        "n = 4\n",
        "for i in range(n):\n",
        "    _ ,  z = gen_DCGAN(6, lambda_rec = lambda_rec)\n",
        "    z = z.cuda()\n",
        "    with torch.no_grad():\n",
        "        fake = netG_600ep(z).cpu()\n",
        "    real_and_fakes.append(fake)\n",
        "\n",
        "real_and_fakes = torch.cat(real_and_fakes,dim=0)\n",
        "fig1 = plt.figure(4, figsize=(36, 6))\n",
        "voir_batch2D(real_and_fakes, 6, fig1, k=0, min_scale=0, max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxKXpYFWqML3"
      },
      "source": [
        "**Exercice n¬∞3** A conditional GAN.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn-dvMLA_x3V"
      },
      "source": [
        "In this exercise, the goal is to implement a conditional Wasserstein-GAN. Once again, theoretical aspects are set aside; the objective is solely to construct the training loop.\n",
        "The context is as follows: we have a set of images representing a domain ùíü.\n",
        "The traditional GAN generates new images from ùíü. In this exercise, we will generate images compatible with a given list of pixel values a priori.\n",
        "\n",
        "The following cells allow visualization of the available dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQEBbOQq_xCz"
      },
      "outputs": [],
      "source": [
        "# Proportion of pixels preserved in yi:\n",
        "obs_density = 0.005\n",
        "\n",
        "x, y, z = gen_condDCGAN(6, obs_density)\n",
        "\n",
        "# Full images xi\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "visualize_2D_batch(x, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Fragmentary images yi: a few pixels randomly sampled from xi\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "visualize_2D_batch(y, 6, fig2, k=0, min_scale=-0.2, max_scale=1)\n",
        "\n",
        "# zi: sample from a centered reduced Gaussian vector\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "visualize_2D_batch(z, 6, fig3, k=0, min_scale=0, max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bOzh1IW_-ud"
      },
      "source": [
        "**Q1** Drawing inspiration from the previous exercise, complete the training loop and run it for ten epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtK8wz6iARji"
      },
      "outputs": [],
      "source": [
        "# SGD Setup\n",
        "batch_size = 128\n",
        "num_batches_generator = 200\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "# Optimizer Parameters\n",
        "lr = 0.0005\n",
        "beta1 = 0.  # SGD momentum\n",
        "\n",
        "# nn setup\n",
        "ndf = 32\n",
        "n_channels = 2\n",
        "n_classes = 1\n",
        "size = 16\n",
        "\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "netD = Discriminator(n_channels).cuda()\n",
        "\n",
        "# optimizers\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQX7RyRrAWPj"
      },
      "outputs": [],
      "source": [
        "real_label = 1.\n",
        "fake_label = 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klbcqnE8AYm7"
      },
      "outputs": [],
      "source": [
        "# To keep track of generated images from a fixed sample of $z_i$:\n",
        "fixed_x, fixed_y, fixed_z = gen_condDCGAN(8, p=dens_obs)\n",
        "\n",
        "# Fixed input for the generator:\n",
        "fixed_yz = torch.cat((fixed_y, fixed_z), dim=1).cuda()\n",
        "\n",
        "# Lists\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "# Other hyperparameters\n",
        "n_critic = 5\n",
        "clip = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1-D_aF-AcCj"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i in range(num_batches_generator):\n",
        "\n",
        "        ############################\n",
        "        # (1) Maximization of log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        netG.train()\n",
        "        # Here, we perform multiple (n_critic) optimization steps for the discriminator.\n",
        "        for j in range(n_critic):\n",
        "\n",
        "            x, y, z = gen_condDCGAN(batch_size, p=dens_obs)\n",
        "\n",
        "            # Move to GPU\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "            z = z.cuda()\n",
        "\n",
        "            # Concatenations:\n",
        "            xy = torch.cat((x, y))\n",
        "            yz = torch.cat((y, z))\n",
        "\n",
        "            output_xy = netD(xy)\n",
        "\n",
        "            fake = netG(yz)\n",
        "            fake = fake.detach()\n",
        "\n",
        "            fakey = torch.cat((fake, y), dim=1)\n",
        "            output_fakey = netD(fakey)\n",
        "\n",
        "            # Regularization by gradient penalty\n",
        "            gradient_penalty = calculate_gradient_penalty(netD, xy.data, fakey.data)\n",
        "\n",
        "            # Calculate discriminator error and update gradients:\n",
        "            label = torch.full((xy.size(0),), real_label, dtype=torch.float).cuda()\n",
        "            err_D_real = criterion(output_xy.view(-1), label)\n",
        "            errD_real.backward()\n",
        "            label.fill_(fake_label)\n",
        "            errD_fake = criterion(output_fakey, label)\n",
        "            errD_fake.backward()\n",
        "\n",
        "            errD = err_D_real + errD_fake  # In case we want to store it later\n",
        "\n",
        "            optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # Maximization of log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "\n",
        "        fake = netD(fake).view(-1)\n",
        "        fakey = torch.cat((fake, y), dim=1)\n",
        "\n",
        "        output_fakey = netD(fakey)\n",
        "\n",
        "        errG = -output_fakey.mean()\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i, num_batches_generator,\n",
        "                     errD.item()))\n",
        "\n",
        "        # Record losses\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(-errD.item())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        netG.eval()\n",
        "        fake = netG(fixed_yz.cuda()).detach().cpu()\n",
        "\n",
        "    img_list.append(fake)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7jeF2FAjDC"
      },
      "source": [
        "**Q2** Visualize some images and comment on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRxifP75AgQM"
      },
      "outputs": [],
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1QHK-AGApMr"
      },
      "source": [
        "**Q3** To obtain a GAN that takes into account the condition contained in $y_i$, it is necessary to push the training further. The file *netG_180ep_WGP_scheduler75_lr005.pt* contains the weights obtained after training for 300 epochs. Load these weights and visualize several images for the same inputs $x_i$ and $z_i$. Check the coherence and draw conclusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH81OZsMAot9"
      },
      "outputs": [],
      "source": [
        "weights = torch.load('netG_180ep_WGP_scheduler75_lr005.pt')\n",
        "netG = UNet(2, 1, 16).cuda()\n",
        "netG.load_state_dict(weights['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73UgleVAyXb"
      },
      "outputs": [],
      "source": [
        "netG.eval()\n",
        "\n",
        "x , y , z = gen_condDCGAN(6, p = dens_obs)\n",
        "\n",
        "xy = torch.cat((x,y))\n",
        "real_and_fakes = [xy]\n",
        "n=6\n",
        "for i in range(n):\n",
        "    _ , y , z = gen_condDCGAN(6, p = dens_obs)\n",
        "    y = y.cuda()\n",
        "    z = z.cuda()\n",
        "    yz = torch.cat((y,z),dim=1)\n",
        "    with torch.no_grad():\n",
        "      fake = netG(yz).cpu()\n",
        "    real_and_fakes.append(fake)\n",
        "\n",
        "real_and_fakes = torch.cat(real_and_fakes,dim=0)\n",
        "fig1 = plt.figure(4, figsize=(36, 6))\n",
        "voir_batch2D(real_and_fakes, 6, fig1, k=0, min_scale=0, max_scale=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}